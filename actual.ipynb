{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cbcf4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Gemini LLM ready (gemini-2.0-flash)\n",
      "[ok] Gemini embeddings ready (models/text-embedding-004)\n",
      "[ok] Cell 1 complete ‚Äî using Gemini for both reasoning and semantic analysis (no local models).\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 1: Imports + Setup (Gemini-only: LLM + Embeddings) ====\n",
    "\n",
    "# Std libs\n",
    "import os, math, uuid, json, time\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# LangChain utilities we‚Äôll reuse later\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Gemini via LangChain (LLM + Embeddings)\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "\n",
    "# ---------- API key (Gemini) ----------\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GOOGLE_API_KEY\") or os.getenv(\"GEMINI_APIKEY\")\n",
    "if not GEMINI_API_KEY or not GEMINI_API_KEY.strip():\n",
    "    raise RuntimeError(\"Missing Gemini key. Set GEMINI_API_KEY in your environment before running.\")\n",
    "\n",
    "# Make sure downstream libs find the key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "# Avoid ADC fallback confusion\n",
    "os.environ.pop(\"GOOGLE_APPLICATION_CREDENTIALS\", None)\n",
    "\n",
    "\n",
    "# ---------- Model handles ----------\n",
    "# LLM (we‚Äôll keep calls modest; e.g., 1 compact JD snapshot call later)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    api_key=GEMINI_API_KEY,\n",
    ")\n",
    "\n",
    "# Semantic embeddings (Gemini text-embedding-004) ‚Äî used for:\n",
    "# retrieval, role/project similarity, skill matching (OOP‚âàOOPS‚âàobject-oriented programming)\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    ")\n",
    "\n",
    "# ---------- Utilities (no outbound calls here) ----------\n",
    "def cosine_sim(u: List[float], v: List[float]) -> float:\n",
    "    \"\"\"Cosine similarity for two equal-length vectors.\"\"\"\n",
    "    if not u or not v:\n",
    "        return 0.0\n",
    "    dot = sum(a * b for a, b in zip(u, v))\n",
    "    nu = math.sqrt(sum(a * a for a in u))\n",
    "    nv = math.sqrt(sum(b * b for b in v))\n",
    "    if nu == 0 or nv == 0:\n",
    "        return 0.0\n",
    "    return dot / (nu * nv)\n",
    "\n",
    "def _batch(iterable: List[Any], size: int) -> List[List[Any]]:\n",
    "    \"\"\"Yield successive batches of given size from a list.\"\"\"\n",
    "    return [iterable[i : i + size] for i in range(0, len(iterable), size)]\n",
    "\n",
    "def embed_texts(texts: List[str], batch_size: int = 64, sleep_between: float = 0.0) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Embed a list of texts using Gemini embeddings with optional batching.\n",
    "    Keep this function for later cells; do NOT call it here to avoid API usage in Cell 1.\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "    vecs: List[List[float]] = []\n",
    "    for chunk in _batch(texts, batch_size):\n",
    "        # This performs a single embeddings API call per batch\n",
    "        chunk_vecs = embedding_model.embed_documents(chunk)\n",
    "        vecs.extend(chunk_vecs)\n",
    "        if sleep_between:\n",
    "            time.sleep(sleep_between)\n",
    "    return vecs\n",
    "\n",
    "def embed_query(text: str) -> List[float]:\n",
    "    \"\"\"Single-text embedding (used for queries like JD vectors).\"\"\"\n",
    "    return embedding_model.embed_query(text or \"\")\n",
    "\n",
    "print(\"[ok] Gemini LLM ready (gemini-2.0-flash)\")\n",
    "print(\"[ok] Gemini embeddings ready (models/text-embedding-004)\")\n",
    "print(\"[ok] Cell 1 complete ‚Äî using Gemini for both reasoning and semantic analysis (no local models).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] STATE initialized ‚Äî run_id=52d59f5aaedc ‚Üí artifacts: tmp\\52d59f5aaedc\n",
      "[ok] Prompts ready: jd_snapshot_and_gates (1 LLM call), extract_all_from_chunk (per selected chunk).\n",
      "[ok] Cell 2 complete ‚Äî state/options/prompts configured for ATS-style scoring with Gemini-only APIs.\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 2 (updated): State + Options + Prompts (context-rich, domain-agnostic, friendly ATS) ====\n",
    "import re, json, uuid\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List, TypedDict\n",
    "\n",
    "# ---------- User Inputs (set these in your notebook run) ----------\n",
    "# Provide either a file path or raw text for resume/JD. Leave as None if you plan to set later.\n",
    "RESUME_FILE: Optional[str] = \"JALADI ASHISH RESUME_oracle.pdf\"      # e.g. \"/mnt/data/resume.pdf\"\n",
    "RESUME_TEXT: Optional[str] = None      # paste resume text if no file\n",
    "\n",
    "JD_FILE: Optional[str] = None          # e.g. \"/mnt/data/jd.pdf\"\n",
    "JD_TEXT: Optional[str] = \"\"\"\n",
    "üß† Job Title: Associate / Junior Generative AI Engineer (Fresher)\n",
    "Location: [Hybrid / Onsite / Remote ‚Äî e.g., Bangalore, Pune, Hyderabad]\n",
    "Experience: 0‚Äì1 Years\n",
    "Employment Type: Full-time\n",
    "Department: AI / Machine Learning / Product Engineering\n",
    "About the Role\n",
    "\n",
    "We are looking for an enthusiastic and innovative Generative AI Engineer (Fresher) to join our AI team.\n",
    "In this role, you‚Äôll work on designing, fine-tuning, and deploying large language model (LLM)-based applications using frameworks like LangChain, LlamaIndex, and OpenAI APIs. You will collaborate with data scientists, backend engineers, and product teams to build intelligent systems that understand, reason, and generate human-like text and content.\n",
    "\n",
    "This is an exciting opportunity for someone passionate about AI, NLP, and prompt engineering, eager to learn real-world GenAI workflows and contribute to production-ready AI systems.\n",
    "\n",
    "Key Responsibilities\n",
    "\n",
    "Design and implement LLM-powered applications using frameworks such as LangChain, LlamaIndex, or Haystack.\n",
    "\n",
    "Develop prompt engineering pipelines and retrieval-augmented generation (RAG) workflows.\n",
    "\n",
    "Work with vector databases (FAISS, Chroma, Pinecone, Weaviate, Milvus) for semantic search and document retrieval.\n",
    "\n",
    "Fine-tune or adapt open-source LLMs (LLaMA, Mistral, Falcon, Gemma, etc.) for domain-specific tasks.\n",
    "\n",
    "Integrate AI APIs (OpenAI, Anthropic, Google Gemini, etc.) into web or backend systems.\n",
    "\n",
    "Collaborate with backend teams to deploy AI models using FastAPI, Flask, or Streamlit.\n",
    "\n",
    "Analyze and evaluate model performance (precision, recall, BLEU, ROUGE, perplexity, etc.).\n",
    "\n",
    "Write efficient, production-quality Python code for data preprocessing, model integration, and automation.\n",
    "\n",
    "Stay up-to-date with advancements in Generative AI, Transformer architectures, and MLOps practices.\n",
    "\n",
    "Technical Skills (Required)\n",
    "üß© Programming & Tools:\n",
    "\n",
    "Proficiency in Python and experience with libraries like transformers, torch, langchain, sentence-transformers, chromadb.\n",
    "\n",
    "Familiarity with REST APIs and JSON for integrating AI services.\n",
    "\n",
    "Experience with Jupyter Notebooks or VS Code for experimentation.\n",
    "\n",
    "Understanding of data preprocessing, text embeddings, and tokenization.\n",
    "\n",
    "ü§ñ AI/ML Concepts:\n",
    "\n",
    "Basic understanding of:\n",
    "\n",
    "Neural networks and transformers (BERT, GPT, etc.)\n",
    "\n",
    "RAG (Retrieval Augmented Generation)\n",
    "\n",
    "Embeddings & vector search\n",
    "\n",
    "Fine-tuning and model evaluation\n",
    "\n",
    "Awareness of Hugging Face ecosystem and OpenAI API usage.\n",
    "\n",
    "üóÑÔ∏è Databases & Backend:\n",
    "\n",
    "Familiarity with NoSQL / vector databases (Chroma, Pinecone, FAISS, Milvus).\n",
    "\n",
    "Knowledge of FastAPI or Flask for backend integration.\n",
    "\n",
    "Basic understanding of cloud services (AWS, GCP, or Azure).\n",
    "\n",
    "Soft Skills\n",
    "\n",
    "Strong problem-solving and analytical abilities.\n",
    "\n",
    "Curiosity and a learning mindset toward cutting-edge AI technologies.\n",
    "\n",
    "Ability to work collaboratively in a fast-paced environment.\n",
    "\n",
    "Good written and verbal communication skills for technical documentation.\n",
    "\n",
    "Educational Qualifications\n",
    "\n",
    "B.E. / B.Tech / M.Tech / MCA in Computer Science, Artificial Intelligence, Data Science, or related fields.\n",
    "\n",
    "Good understanding of Mathematics, Statistics, and Machine Learning fundamentals.\n",
    "\n",
    "Academic or personal projects related to AI / NLP / LLMs are a plus.\n",
    "\n",
    "Bonus / Nice-to-Have Skills\n",
    "\n",
    "Experience with LangGraph, CrewAI, or OpenDevin-style agent frameworks.\n",
    "\n",
    "Exposure to MLOps pipelines (Docker, MLflow, Hugging Face Hub).\n",
    "\n",
    "Knowledge of document loaders, PDF parsing, or knowledge base QA systems.\n",
    "\n",
    "Understanding of prompt optimization, few-shot learning, and tool use in LLMs.\n",
    "\"\"\"          # paste JD text if no file\n",
    "\n",
    "# ---------- Configuration / thresholds ----------\n",
    "class RunOptions(TypedDict):\n",
    "    # chunking + retrieval\n",
    "    chunk_tokens: int               # approx tokens per chunk (proxy via chars*4)\n",
    "    chunk_overlap: float            # 0..1 overlap ratio\n",
    "    faiss_topk: int                 # how many JD-relevant chunks to use\n",
    "    extract_max_chunks: int         # cap LLM extractions (one call per selected chunk)\n",
    "    hybrid_alpha: float             # weight for semantic vs lexical (0..1, higher = more semantic)\n",
    "    mmr_lambda: float               # MMR diversity weight (0..1), higher = more diversity\n",
    "\n",
    "    # API budgets\n",
    "    llm_budget_calls: int           # total Gemini LLM call budget\n",
    "    embed_batch_size: int           # embeddings batch size per call\n",
    "\n",
    "    # semantic thresholds (embeddings)\n",
    "    strong_sim: float               # cosine ‚â• strong match\n",
    "    partial_sim: float              # cosine ‚â• partial match\n",
    "    canon_threshold: float          # clustering threshold for canonicalizing observed terms\n",
    "\n",
    "    # complexity / transferability\n",
    "    max_projects_for_complexity: int  # max projects to score with LLM (batched once)\n",
    "    complexity_weight_cap: float      # cap added by complexity/transferability bonus (0..1 influence)\n",
    "\n",
    "    # scoring weights (0‚Äì100 total)\n",
    "    weights: Dict[str, float]       # component weights sum ~100\n",
    "    gate_hard_cap: int              # cap score when a hard gate fails\n",
    "\n",
    "    # eligibility + UX\n",
    "    eligibility_threshold: int      # eligible if score_100 ‚â• this\n",
    "    sections_to_emit: List[str]     # three sections for frontend\n",
    "\n",
    "    # misc\n",
    "    recency_months_ideal: int       # months considered freshest for roles\n",
    "    language: str                   # hint for JD/resume language (e.g., \"en\")\n",
    "    keep_artifacts: bool            # write intermediate JSONs to ./tmp\n",
    "\n",
    "DEFAULT_OPTIONS: RunOptions = {\n",
    "    # retrieval\n",
    "    \"chunk_tokens\": 900,\n",
    "    \"chunk_overlap\": 0.15,\n",
    "    \"faiss_topk\": 8,\n",
    "    \"extract_max_chunks\": 4,\n",
    "    \"hybrid_alpha\": 0.6,      # 60% semantic, 40% lexical\n",
    "    \"mmr_lambda\": 0.35,\n",
    "\n",
    "    # budgets\n",
    "    \"llm_budget_calls\": 7,    # JD snapshot (1) + per-chunk (‚â§4) + consolidation (1) + complexity batch (1)\n",
    "    \"embed_batch_size\": 64,\n",
    "\n",
    "    # semantic thresholds\n",
    "    \"strong_sim\": 0.78,\n",
    "    \"partial_sim\": 0.65,\n",
    "    \"canon_threshold\": 0.82,\n",
    "\n",
    "    # complexity / transferability\n",
    "    \"max_projects_for_complexity\": 4,\n",
    "    \"complexity_weight_cap\": 0.12,   # at most +12 points influence\n",
    "\n",
    "    # scoring weights (sum to ~100)\n",
    "    \"weights\": {\n",
    "        \"must_have_coverage\": 22.0,\n",
    "        \"required_coverage\": 16.0,\n",
    "        \"preferred_coverage\": 6.0,\n",
    "        \"role_alignment\": 16.0,\n",
    "        \"project_alignment\": 10.0,\n",
    "        \"evidence_depth\": 6.0,\n",
    "        \"seniority_fit\": 8.0,\n",
    "        \"responsibility_overlap\": 6.0,\n",
    "        \"transferability_bonus\": 10.0,  # complexity √ó transferability\n",
    "    },\n",
    "    \"gate_hard_cap\": 59,\n",
    "\n",
    "    # eligibility + UX\n",
    "    \"eligibility_threshold\": 50,   # ‚â• 50 is eligible\n",
    "    \"sections_to_emit\": [\n",
    "        \"present_against_jd\",      # what‚Äôs present (must/required/preferred with evidence)\n",
    "        \"missing_against_jd\",      # gaps vs JD\n",
    "        \"extra_strengths\"          # additional strengths (complex/transferable projects, internships, certs)\n",
    "    ],\n",
    "\n",
    "    # misc\n",
    "    \"recency_months_ideal\": 6,\n",
    "    \"language\": \"en\",\n",
    "    \"keep_artifacts\": True,\n",
    "}\n",
    "\n",
    "# ---------- Pipeline STATE ----------\n",
    "class PipelineState(TypedDict, total=False):\n",
    "    run_id: str\n",
    "    options: RunOptions\n",
    "    inputs: Dict[str, Optional[str]]\n",
    "    raw: Dict[str, Optional[str]]\n",
    "    provenance: Dict[str, Any]\n",
    "    chunks: List[Dict[str, Any]]\n",
    "    faiss: Dict[str, Any]\n",
    "    contacts: Dict[str, Any]\n",
    "    high_level: Dict[str, Any]\n",
    "    education: List[Dict[str, Any]]\n",
    "    timeline: List[Dict[str, Any]]\n",
    "    projects: List[Dict[str, Any]]\n",
    "    skills: List[Dict[str, Any]]\n",
    "    certs: List[Dict[str, Any]]\n",
    "    awards: List[Dict[str, Any]]\n",
    "    locations: List[str]\n",
    "    jd_snapshot: Dict[str, Any]\n",
    "    canon: Dict[str, Any]\n",
    "    jd_alignment: Dict[str, Any]\n",
    "    coverage: Dict[str, Any]\n",
    "    gates: Dict[str, Any]\n",
    "    complexity: Dict[str, Any]\n",
    "    final: Dict[str, Any]\n",
    "    artifacts: Dict[str, Any]\n",
    "    audit: List[str]\n",
    "    _llm_calls: int\n",
    "\n",
    "def new_state(\n",
    "    resume_file: Optional[str],\n",
    "    resume_text: Optional[str],\n",
    "    jd_file: Optional[str],\n",
    "    jd_text: Optional[str],\n",
    "    options: RunOptions = DEFAULT_OPTIONS,\n",
    ") -> PipelineState:\n",
    "    run_id = uuid.uuid4().hex[:12]\n",
    "    base_dir = Path(f\"./tmp/{run_id}\")\n",
    "    paths = {\n",
    "        \"base_dir\": str(base_dir),\n",
    "        \"chunks_json\": str(base_dir / \"chunks.json\"),\n",
    "        \"entities_by_chunk_json\": str(base_dir / \"entities_by_chunk.json\"),\n",
    "        \"final_json\": str(base_dir / \"final.json\"),\n",
    "        \"faiss_dir\": str(base_dir / \"faiss\"),\n",
    "        \"jd_snapshot_json\": str(base_dir / \"jd_snapshot.json\"),\n",
    "        \"complexity_json\": str(base_dir / \"complexity.json\"),\n",
    "    }\n",
    "    st: PipelineState = {\n",
    "        \"run_id\": run_id,\n",
    "        \"options\": options,\n",
    "        \"inputs\": {\n",
    "            \"resume_file\": resume_file, \"resume_text\": resume_text,\n",
    "            \"jd_file\": jd_file, \"jd_text\": jd_text,\n",
    "        },\n",
    "        \"raw\": {\"resume_text\": None, \"jd_text\": None},\n",
    "        \"provenance\": {\"chunks\": [], \"hybrid_retrieval\": [], \"mmr_selected\": []},\n",
    "        \"chunks\": [],\n",
    "        \"faiss\": {\"index_path\": None, \"topk_ids\": []},\n",
    "        \"contacts\": {\"name\": None, \"email\": None, \"phone\": None,\n",
    "                     \"links\": {\"linkedin\": None, \"github\": None, \"portfolio\": None, \"website\": None}},\n",
    "        \"high_level\": {\"summary\": None, \"location\": None, \"years_experience\": None},\n",
    "        \"education\": [], \"timeline\": [], \"projects\": [],\n",
    "        \"skills\": [], \"certs\": [], \"awards\": [], \"locations\": [],\n",
    "        \"jd_snapshot\": {\n",
    "            \"title\": None,\n",
    "            \"must_haves\": [],\n",
    "            \"required\": [],\n",
    "            \"preferred\": [],\n",
    "            \"responsibilities\": [],\n",
    "            \"hard_gates\": {\n",
    "                \"degree_required\": False,\n",
    "                \"min_years\": None,\n",
    "                \"license\": [],\n",
    "                \"work_auth\": None,\n",
    "                \"clearance\": None,\n",
    "                \"location_mode\": None,\n",
    "                \"onsite_city\": None,\n",
    "                \"shift\": None,\n",
    "                \"travel\": None,\n",
    "            },\n",
    "            \"evidence\": {\"must\": {}, \"req\": {}, \"pref\": {}, \"resp\": {}},\n",
    "            \"conf\": {\"must\": {}, \"req\": {}, \"pref\": {}, \"resp\": {}},\n",
    "        },\n",
    "        \"canon\": {\n",
    "            \"skill_alias\": {},              # NO domain hardcoding; embeddings will unify semantics later\n",
    "            \"normalized_skills\": [],\n",
    "            \"normalized_required\": [],\n",
    "            \"normalized_preferred\": [],\n",
    "        },\n",
    "        \"jd_alignment\": {\n",
    "            \"must_have\": [],\n",
    "            \"required\": [],\n",
    "            \"preferred\": [],\n",
    "            \"responsibilities\": {\"coverage\": 0.0, \"count\": 0}\n",
    "        },\n",
    "        \"coverage\": {},\n",
    "        \"gates\": {\"failed\": [], \"notes\": []},\n",
    "        \"complexity\": {\"scored\": [], \"bonus\": 0.0},\n",
    "        \"final\": {},\n",
    "        \"artifacts\": {\"base_dir\": paths[\"base_dir\"], \"paths\": paths},\n",
    "        \"audit\": [],\n",
    "        \"_llm_calls\": 0,\n",
    "    }\n",
    "    if options.get(\"keep_artifacts\", True):\n",
    "        base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"[ok] STATE initialized ‚Äî run_id={st['run_id']} ‚Üí artifacts: {paths['base_dir']}\")\n",
    "    return st\n",
    "\n",
    "STATE = new_state(RESUME_FILE, RESUME_TEXT, JD_FILE, JD_TEXT, DEFAULT_OPTIONS)\n",
    "\n",
    "# ---------- Prompt helpers ----------\n",
    "def _escape_braces_keep_vars(template: str, keep_vars: List[str]) -> str:\n",
    "    esc = template.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    for v in keep_vars:\n",
    "        esc = esc.replace(\"{{\" + v + \"}}\", \"{\" + v + \"}\")\n",
    "    return esc\n",
    "\n",
    "PROMPTS: Dict[str, str] = {}\n",
    "\n",
    "# 1) JD snapshot + hard gates (detailed, domain-agnostic, evidence-bound, friendly to implied tokens)\n",
    "PROMPTS[\"jd_snapshot_and_gates\"] = _escape_braces_keep_vars(r\"\"\"\n",
    "You are a **strict but fair** parser for an Applicant Tracking System. Read the Job Description (any domain)\n",
    "and convert it into a compact, **evidence-bound** JSON snapshot used for automated matching.\n",
    "\n",
    "General rules:\n",
    "- Tokens must be **atomic capabilities/credentials**, in **lowercase** (e.g., \"object oriented programming\", \"excel\", \"b2b sales\", \"sterile technique\", \"lean six sigma\").\n",
    "- Include items that are **explicit** or **clearly implied** by phrasing; do **NOT** list examples not present.\n",
    "- Do **NOT** expand families (no listing \"gcc/clang\" if only \"compilers\" is mentioned).\n",
    "- For every token/phrase/gate, supply a short **evidence** snippet (‚â§160 chars). If unclear, use \"\".\n",
    "- Include a **confidence** score (0.0‚Äì1.0) reflecting how certain the token/phrase was required or implied.\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{\n",
    "  \"title\": \"<short role title>\",\n",
    "  \"must_haves\": [{\"token\": \"\", \"evidence\": \"\", \"conf\": 0.0}],\n",
    "  \"required\": [{\"token\": \"\", \"evidence\": \"\", \"conf\": 0.0}],\n",
    "  \"preferred\": [{\"token\": \"\", \"evidence\": \"\", \"conf\": 0.0}],\n",
    "  \"responsibilities\": [{\"phrase\": \"\", \"evidence\": \"\", \"conf\": 0.0}],\n",
    "  \"hard_gates\": {\n",
    "    \"degree_required\": { \"value\": true|false, \"evidence\": \"\" },\n",
    "    \"min_years\": { \"value\": null | 0, \"evidence\": \"\" },\n",
    "    \"license\": [{ \"token\": \"\", \"evidence\": \"\" }],\n",
    "    \"work_auth\": { \"value\": null | \"us citizen|eu work permit|...\", \"evidence\": \"\" },\n",
    "    \"clearance\": { \"value\": null | \"active secret|public trust|...\", \"evidence\": \"\" },\n",
    "    \"location_mode\": { \"value\": null | \"onsite|hybrid|remote\", \"evidence\": \"\" },\n",
    "    \"onsite_city\": { \"value\": null | \"<city or region>\", \"evidence\": \"\" },\n",
    "    \"shift\": { \"value\": null | \"night|rotational|weekend|...\", \"evidence\": \"\" },\n",
    "    \"travel\": { \"value\": null | \"<% or phrase>\", \"evidence\": \"\" }\n",
    "  }\n",
    "}\n",
    "\n",
    "Guidance:\n",
    "- Prefer role-agnostic phrasing; avoid technology bias. Examples across domains: \"inventory optimization\", \"sterile technique\", \"crm\", \"lead generation\", \"risk analysis\", \"six sigma\", \"autocad\", \"wound care\".\n",
    "- Keep lists **minimal & atomic**; never merge two different tokens into one.\n",
    "\n",
    "JD:\n",
    "---\n",
    "{jd_text}\n",
    "---\n",
    "\"\"\", [\"jd_text\"])\n",
    "\n",
    "# 2) Chunk extractor (one call per selected chunk) ‚Äî capture verbatim items + short evidence per entry\n",
    "PROMPTS[\"extract_all_from_chunk\"] = _escape_braces_keep_vars(r\"\"\"\n",
    "Extract **only** what appears in THIS chunk of a resume. Do not infer content from outside this chunk.\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{\n",
    "  \"contacts\": { \"name\": null, \"email\": null, \"phone\": null, \"links\": [\"urls\"] },\n",
    "  \"education\": [\n",
    "    { \"degree\": \"\", \"field\": \"\", \"institution\": \"\", \"start\": null, \"end\": null, \"location\": null, \"evidence\": \"\" }\n",
    "  ],\n",
    "  \"experience\": [\n",
    "    { \"title\": \"\", \"company\": \"\", \"location\": null, \"start\": null, \"end\": null,\n",
    "      \"highlights\": [\"impact/achievements, keep concise; include metrics if any\"], \"evidence\": \"\" }\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    { \"name\": \"\", \"tech\": [\"as written tokens\"], \"impact\": null, \"duration\": null, \"role\": null, \"links\": [\"urls\"], \"evidence\": \"\" }\n",
    "  ],\n",
    "  \"skills\": [\"as written tokens\"],\n",
    "  \"certifications\": [\"as written short tokens\"],\n",
    "  \"awards\": [\"as written\"],\n",
    "  \"locations\": [\"city/state/country names mentioned\"]\n",
    "}\n",
    "\n",
    "Chunk ID: {chunk_id}\n",
    "Chunk:\n",
    "---\n",
    "{chunk_text}\n",
    "---\n",
    "\"\"\", [\"chunk_id\",\"chunk_text\"])\n",
    "\n",
    "# 3) Consolidator (single call) ‚Äî dedupe, unify synonyms ONLY if evidenced; keep multiple evidences\n",
    "PROMPTS[\"consolidate_resume_json\"] = _escape_braces_keep_vars(r\"\"\"\n",
    "You are merging multiple chunk-level JSON extractions of one resume.\n",
    "\n",
    "Rules:\n",
    "- **Deduplicate** across chunks.\n",
    "- **Unify obvious synonyms** ONLY if each synonym has some evidence (e.g., \"o.o.p\", \"oop\", \"object oriented programming\").\n",
    "  Use a single **canonical** string; keep all synonyms in **aliases**.\n",
    "- **Keep evidence arrays** for each item (gather from input snippets).\n",
    "- Normalize dates to \"YYYY-MM\" when possible; if ambiguous, retain the raw string.\n",
    "- Preserve short, high-signal highlights (metrics, scale, scope).\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{\n",
    "  \"contacts\": { \"name\": null, \"email\": null, \"phone\": null, \"links\": [\"urls\"] },\n",
    "  \"education\": [ { \"degree\": \"\", \"field\": \"\", \"institution\": \"\", \"start\": null, \"end\": null, \"location\": null, \"evidence\": [\"...\"] } ],\n",
    "  \"experience\": [ { \"title\": \"\", \"company\": \"\", \"location\": null, \"start\": null, \"end\": null, \"highlights\": [\"...\"], \"evidence\": [\"...\"] } ],\n",
    "  \"projects\": [ { \"name\": \"\", \"tech\": [\"tokens\"], \"impact\": null, \"duration\": null, \"role\": null, \"links\": [\"urls\"], \"evidence\": [\"...\"] } ],\n",
    "  \"skills\": [ { \"canonical\": \"\", \"aliases\": [\"...\"], \"evidence\": [\"...\"] } ],\n",
    "  \"certifications\": [ { \"canonical\": \"\", \"aliases\": [\"...\"], \"evidence\": [\"...\"] } ],\n",
    "  \"awards\": [ { \"canonical\": \"\", \"evidence\": [\"...\"] } ],\n",
    "  \"locations\": [ { \"canonical\": \"\", \"evidence\": [\"...\"] } ]\n",
    "}\n",
    "\n",
    "Inputs:\n",
    "---\n",
    "{chunk_json}\n",
    "---\n",
    "\"\"\", [\"chunk_json\"])\n",
    "\n",
    "# 4) Project/Internship complexity & transferability scorer (batched once for top-N projects)\n",
    "PROMPTS[\"score_project_complexity_batch\"] = _escape_braces_keep_vars(r\"\"\"\n",
    "Evaluate each PROJECT/INTERNSHIP against the Job Description **in principle** (domain-agnostic).\n",
    "Score two axes from 0.0‚Äì1.0, and provide a concise rationale:\n",
    "\n",
    "- \"complexity\": problem difficulty, scale (#users, data/transactions), technical or domain depth,\n",
    "  constraints (latency, safety, compliance), duration/tenure, ownership, novelty, integration breadth.\n",
    "- \"transferability\": how well the **capabilities and patterns** demonstrated can apply to the JD role, even if the domain differs\n",
    "  (e.g., experimentation, stakeholder comms, process automation, safety standards, optimization, data handling,\n",
    "   customer workflows, regulations, reliability, cost control, quality metrics, design-to-constraints).\n",
    "\n",
    "Important:\n",
    "- Do NOT penalize domain mismatch if fundamentals/approaches are transferable.\n",
    "- Use the project text only (no invention). Prefer metrics when present.\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{\n",
    "  \"items\": [\n",
    "    { \"name\": \"\", \"complexity\": 0.0, \"transferability\": 0.0, \"rationale\": \"1‚Äì2 lines grounded in the text\" }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Context:\n",
    "JD_title: {jd_title}\n",
    "JD_tokens: {jd_tokens}\n",
    "\n",
    "PROJECTS_JSON:\n",
    "---\n",
    "{projects_json}\n",
    "---\n",
    "\"\"\", [\"jd_title\",\"jd_tokens\",\"projects_json\"])\n",
    "\n",
    "print(\"[ok] Prompts ready (detailed, domain-agnostic): jd_snapshot_and_gates, extract_all_from_chunk, consolidate_resume_json, score_project_complexity_batch\")\n",
    "print(\"[ok] Cell 2 updated ‚Äî context-aware, not strict, supports project complexity/transferability, eligibility ‚â• 50.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edfb6d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Chunked resume into 2 chunks\n",
      "[ok] Hybrid JD-relevant chunks (top-2): ['c_01', 'c_00']\n",
      "[ok] Detector ‚Üí resume-like\n",
      "[ok] Resume confirmed ‚Äî proceed to Cell 4 (strict JD snapshot + batched AI extraction).\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 3 (updated): Load ‚Üí Chunk ‚Üí Batched Embeddings ‚Üí Hybrid Retrieval ‚Üí Resume Sanity ====\n",
    "import json, re, zipfile, xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Ensure flags exists\n",
    "STATE.setdefault(\"flags\", {})\n",
    "STATE[\"flags\"].setdefault(\"is_resume\", False)\n",
    "\n",
    "# --- helpers: file reading ---\n",
    "def read_pdf_pymupdf(path: str) -> str:\n",
    "    loader = PyMuPDFLoader(path)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\".join((d.page_content or \"\") for d in docs)\n",
    "\n",
    "def read_docx_quick(path: str) -> str:\n",
    "    with zipfile.ZipFile(path) as z:\n",
    "        xml_bytes = z.read(\"word/document.xml\")\n",
    "    root = ET.fromstring(xml_bytes)\n",
    "    ns = {\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n",
    "    lines = []\n",
    "    for p in root.findall(\".//w:p\", ns):\n",
    "        txt = \"\".join((t.text or \"\") for t in p.findall(\".//w:t\", ns)).strip()\n",
    "        if txt:\n",
    "            lines.append(txt)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def read_text_file(path: str) -> str:\n",
    "    return Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def read_any(path_or_text: Optional[str]) -> str:\n",
    "    \"\"\"Accept either a filesystem path or raw text.\"\"\"\n",
    "    if not path_or_text:\n",
    "        return \"\"\n",
    "    p = Path(path_or_text)\n",
    "    if p.exists():\n",
    "        ext = p.suffix.lower()\n",
    "        if ext == \".pdf\":  return read_pdf_pymupdf(str(p))\n",
    "        if ext == \".docx\": return read_docx_quick(str(p))\n",
    "        return read_text_file(str(p))\n",
    "    return str(path_or_text)\n",
    "\n",
    "# --- ensure artifacts dir ---\n",
    "paths = STATE[\"artifacts\"][\"paths\"]\n",
    "base_dir = Path(paths[\"base_dir\"])\n",
    "if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- load resume & JD into STATE[\"raw\"] ---\n",
    "resume_text = STATE[\"raw\"].get(\"resume_text\") or (\n",
    "    read_any(STATE[\"inputs\"].get(\"resume_file\")) if STATE[\"inputs\"].get(\"resume_file\") else read_any(STATE[\"inputs\"].get(\"resume_text\"))\n",
    ")\n",
    "jd_text = STATE[\"raw\"].get(\"jd_text\") or (\n",
    "    read_any(STATE[\"inputs\"].get(\"jd_file\")) if STATE[\"inputs\"].get(\"jd_file\") else read_any(STATE[\"inputs\"].get(\"jd_text\"))\n",
    ")\n",
    "\n",
    "if not resume_text.strip():\n",
    "    raise RuntimeError(\"No resume content found. Provide RESUME_FILE or RESUME_TEXT in Cell 2.\")\n",
    "if not jd_text.strip():\n",
    "    raise RuntimeError(\"No JD content found. Provide JD_FILE or JD_TEXT in Cell 2.\")\n",
    "\n",
    "STATE[\"raw\"][\"resume_text\"] = resume_text\n",
    "STATE[\"raw\"][\"jd_text\"] = jd_text\n",
    "\n",
    "# --- chunking (char proxy for tokens) ---\n",
    "opts = STATE[\"options\"]\n",
    "chunk_chars = int(opts[\"chunk_tokens\"] * 4)  # ~4 chars/token\n",
    "overlap_chars = int(chunk_chars * opts[\"chunk_overlap\"])\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_chars,\n",
    "    chunk_overlap=overlap_chars,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    ")\n",
    "chunks_texts: List[str] = splitter.split_text(resume_text)\n",
    "STATE[\"chunks\"] = [{\"id\": f\"c_{i:02d}\", \"text\": t} for i, t in enumerate(chunks_texts)]\n",
    "\n",
    "if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "    with open(paths[\"chunks_json\"], \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(STATE[\"chunks\"], f, ensure_ascii=False, indent=2)\n",
    "print(f\"[ok] Chunked resume into {len(STATE['chunks'])} chunks\")\n",
    "\n",
    "# --- Batched embeddings (Gemini) for all chunks (one batched op, not per-chunk) ---\n",
    "texts = [c[\"text\"] for c in STATE[\"chunks\"]]\n",
    "chunk_vecs = embed_texts(texts, batch_size=opts.get(\"embed_batch_size\", 64))  # batched\n",
    "STATE[\"provenance\"][\"chunk_vecs\"] = None  # don‚Äôt persist big arrays by default\n",
    "# (Keep vectors in memory only; avoids artifact bloat)\n",
    "\n",
    "# --- Hybrid retrieval: semantic (cosine) + lexical coverage (JD tokens) ---\n",
    "# Rationale: robust retrieval mixes semantics with lexical overlap; avoids overweighting generic semantics.\n",
    "# See enterprise guidance on combining semantic + traditional scores.  # refs in comments\n",
    "def _lex_keywords(s: str) -> List[str]:\n",
    "    s = re.sub(r\"[^A-Za-z0-9+#.\\-/ ]+\", \" \", s.lower())\n",
    "    toks = [t for t in s.split() if len(t) >= 3]\n",
    "    # keep symbols like c++, c#, .net as tokens too\n",
    "    return list(dict.fromkeys(toks))\n",
    "\n",
    "jd_tokens = _lex_keywords(jd_text)\n",
    "jd_token_set = set(jd_tokens)\n",
    "\n",
    "# precompute lexical scores per chunk = (# JD tokens present) / (sqrt(len(chunk_tokens)) to damp long chunks)\n",
    "lex_scores = []\n",
    "for c in STATE[\"chunks\"]:\n",
    "    toks = set(_lex_keywords(c[\"text\"]))\n",
    "    overlap = len(jd_token_set.intersection(toks))\n",
    "    norm = max(1.0, (len(toks) ** 0.5))\n",
    "    lex_scores.append(overlap / norm)\n",
    "\n",
    "# semantic scores via cosine with single JD query vector\n",
    "jd_vec = embed_query(jd_text[:4000])\n",
    "sem_scores = [cosine_sim(v, jd_vec) for v in chunk_vecs]\n",
    "\n",
    "# combine (alpha semantic, (1-alpha) lexical) ‚Üí select top-k\n",
    "alpha = 0.6  # heavier weight to semantic; lexical still matters\n",
    "# normalize lexical to [0,1]\n",
    "lex_max = max(lex_scores) if lex_scores else 1.0\n",
    "lex_norm = [ls / (lex_max or 1.0) for ls in lex_scores]\n",
    "combo = [alpha * s + (1 - alpha) * l for s, l in zip(sem_scores, lex_norm)]\n",
    "\n",
    "ranked_idx = sorted(range(len(combo)), key=lambda i: combo[i], reverse=True)\n",
    "topk = max(1, min(opts[\"faiss_topk\"], len(ranked_idx)))\n",
    "sel_idx = ranked_idx[:topk]\n",
    "STATE[\"faiss\"][\"topk_ids\"] = [STATE[\"chunks\"][i][\"id\"] for i in sel_idx]\n",
    "\n",
    "# Save a tiny audit\n",
    "hybrid_audit = [\n",
    "    {\"id\": STATE[\"chunks\"][i][\"id\"], \"semantic\": round(sem_scores[i], 3), \"lexical\": round(lex_norm[i], 3), \"score\": round(combo[i], 3)}\n",
    "    for i in sel_idx\n",
    "]\n",
    "STATE[\"provenance\"][\"hybrid_retrieval\"] = hybrid_audit\n",
    "if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "    with open(base_dir / \"hybrid_scores.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(hybrid_audit, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"[ok] Hybrid JD-relevant chunks (top-{len(STATE['faiss']['topk_ids'])}): {STATE['faiss']['topk_ids']}\")\n",
    "\n",
    "# --- resume/not_resume detector (LOCAL heuristic; no LLM call) ---\n",
    "lower = resume_text.lower()\n",
    "signals = sum([\n",
    "    bool(re.search(r\"\\beducation\\b\", lower)),\n",
    "    bool(re.search(r\"\\bexperience\\b|\\bwork\\b\", lower)),\n",
    "    bool(re.search(r\"\\bskills?\\b\", lower)),\n",
    "    bool(re.search(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", resume_text)),\n",
    "])\n",
    "STATE[\"flags\"][\"is_resume\"] = bool(signals >= 2 or len(resume_text.split()) > 150)\n",
    "STATE[\"audit\"].append(f\"resume_detector.local={STATE['flags']['is_resume']}; signals={signals}\")\n",
    "\n",
    "print(f\"[ok] Detector ‚Üí {'resume-like' if STATE['flags']['is_resume'] else 'not-resume'}\")\n",
    "if not STATE[\"flags\"][\"is_resume\"]:\n",
    "    STATE[\"final\"] = {\n",
    "        \"score_100\": 0,\n",
    "        \"selected\": False,\n",
    "        \"breakdown\": {},\n",
    "        \"reasons\": [\"Document did not appear to be a resume (insufficient structural signals).\"],\n",
    "        \"strong_matches\": [],\n",
    "        \"skill_gaps\": [],\n",
    "        \"risk_flags\": [\"resume_detector_failed\"]\n",
    "    }\n",
    "    if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "        with open(paths[\"final_json\"], \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(STATE[\"final\"], f, ensure_ascii=False, indent=2)\n",
    "    print(\"[END] not_resume ‚Üí score=0. Stop here.\")\n",
    "else:\n",
    "    print(\"[ok] Resume confirmed ‚Äî proceed to Cell 4 (strict JD snapshot + batched AI extraction).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7478ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] JD snapshot (strict) ready; no expansions were allowed.\n",
      "[ok] Planning extraction for 2 chunk(s) within budget (used=1/6).\n",
      "[ok] Strict extraction + consolidation + semantic alignment complete.\n",
      "  - roles: 1, projects: 4, skills (canonical observed): 14\n",
      "  - alignment: must_have=12, req=0, pref=7\n",
      "  - responsibilities coverage‚âà100%\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 4 (fixed): Strict JD snapshot ‚Üí Batched LLM extraction (evidence) ‚Üí Consolidation ‚Üí Semantic alignment ====\n",
    "# API plan:\n",
    "#   ‚Ä¢ 1x LLM call: strict JD snapshot (NO expansions; evidence-bound)\n",
    "#   ‚Ä¢ ‚â§N x LLM calls: per-chunk extraction (N = extract_max_chunks & budget)\n",
    "#   ‚Ä¢ 1x LLM call: consolidation (dedupe & synonym unify only when evidence exists)\n",
    "# Embeddings are batched (Gemini) for matching; no extra LLM for matching.\n",
    "\n",
    "import json, re\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ---------------- helpers & budget ----------------\n",
    "def _json_loose(s: str) -> Any:\n",
    "    s = (s or \"\").strip()\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}|\\[.*\\]\", s, flags=re.S)\n",
    "        if m:\n",
    "            return json.loads(m.group(0))\n",
    "        raise\n",
    "\n",
    "def _budget_ok(n: int = 1) -> bool:\n",
    "    return STATE[\"_llm_calls\"] + n <= STATE[\"options\"][\"llm_budget_calls\"]\n",
    "\n",
    "def _bump(n: int = 1):\n",
    "    STATE[\"_llm_calls\"] += n\n",
    "\n",
    "def _clip(s: Optional[str], n: int = 1200) -> str:\n",
    "    if not s: return \"\"\n",
    "    s = str(s)\n",
    "    return s if len(s) <= n else s[:n]\n",
    "\n",
    "def _now() -> datetime:\n",
    "    return datetime.utcnow()\n",
    "\n",
    "# date parser (defined early so we can use it later)\n",
    "def _parse_date_soft(s: Optional[str]) -> Optional[datetime]:\n",
    "    \"\"\"Forgiving date parser; supports 'MMM YYYY', 'YYYY', 'Present'.\"\"\"\n",
    "    if not s: return None\n",
    "    tl = str(s).strip().lower()\n",
    "    if any(k in tl for k in [\"present\", \"current\", \"now\"]):\n",
    "        return _now()\n",
    "    try:\n",
    "        from dateutil import parser as _dp\n",
    "        dt = _dp.parse(tl, default=datetime(2000,1,1), fuzzy=True)\n",
    "        if 1900 <= dt.year <= 2100:\n",
    "            return datetime(dt.year, dt.month if dt.month else 1, 1)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r\"(20\\d{2}|19\\d{2})\", tl)\n",
    "    if m:\n",
    "        return datetime(int(m.group(1)), 1, 1)\n",
    "    return None\n",
    "\n",
    "def _months_between(a: Optional[datetime], b: Optional[datetime]) -> int:\n",
    "    if not a or not b: return 0\n",
    "    return max(0, (b.year - a.year) * 12 + (b.month - a.month))\n",
    "\n",
    "# ---------------- 1) STRICT JD snapshot (1 LLM call; no expansions; with evidence) ----------------\n",
    "JD_PROMPT_STRICT = r\"\"\"\n",
    "You are assisting an Applicant Tracking System.\n",
    "\n",
    "TASK: Convert the Job Description into a STRICT, EVIDENCE-BOUND JSON snapshot.\n",
    "RULES (read carefully):\n",
    "- Do NOT invent or expand lists. Only include items that appear EXPLICITLY in the JD text.\n",
    "- If a family is mentioned (e.g., \"compilers\"), record the family term ONLY, do NOT enumerate (no \"gcc\", \"clang\" unless written).\n",
    "- Tokens should be atomic capability/credential terms in lowercase.\n",
    "- Provide a short evidence snippet (<=160 chars) for every token and gate you return.\n",
    "\n",
    "Return STRICT JSON ONLY:\n",
    "{\n",
    "  \"title\": \"<short>\",\n",
    "  \"must_haves\": [{\"token\": \"\", \"evidence\": \"\"}],\n",
    "  \"required\":    [{\"token\": \"\", \"evidence\": \"\"}],\n",
    "  \"preferred\":   [{\"token\": \"\", \"evidence\": \"\"}],\n",
    "  \"responsibilities\": [{\"phrase\": \"\", \"evidence\": \"\"}],\n",
    "  \"hard_gates\": {\n",
    "    \"degree_required\": { \"value\": true|false, \"evidence\": \"\" },\n",
    "    \"min_years\": { \"value\": null | 0, \"evidence\": \"\" },\n",
    "    \"license\": [{ \"token\": \"\", \"evidence\": \"\" }],\n",
    "    \"work_auth\": { \"value\": null | \"us citizen|eu work permit|...\", \"evidence\": \"\" },\n",
    "    \"clearance\": { \"value\": null | \"active secret|...\", \"evidence\": \"\" },\n",
    "    \"location_mode\": { \"value\": null | \"onsite|hybrid|remote\", \"evidence\": \"\" },\n",
    "    \"onsite_city\": { \"value\": null | \"<city>\", \"evidence\": \"\" },\n",
    "    \"shift\": { \"value\": null | \"night|rotational|...\", \"evidence\": \"\" },\n",
    "    \"travel\": { \"value\": null | \"<% or phrase>\", \"evidence\": \"\" }\n",
    "  }\n",
    "}\n",
    "\n",
    "JD:\n",
    "---\n",
    "{jd_text}\n",
    "---\n",
    "\"\"\"\n",
    "# escape braces for LangChain template (only keep {jd_text} as a variable)\n",
    "JD_PROMPT_STRICT = _escape_braces_keep_vars(JD_PROMPT_STRICT, [\"jd_text\"])\n",
    "\n",
    "if not STATE[\"jd_snapshot\"].get(\"required\") and _budget_ok(1):\n",
    "    jd_prompt = ChatPromptTemplate.from_template(JD_PROMPT_STRICT)\n",
    "    jd_chain = jd_prompt | llm\n",
    "    jd_raw = jd_chain.invoke({\"jd_text\": STATE[\"raw\"][\"jd_text\"]})\n",
    "    _bump(1)\n",
    "    obj = _json_loose(getattr(jd_raw, \"content\", str(jd_raw)))\n",
    "\n",
    "    # Normalize & store (lists + evidence maps)\n",
    "    js = STATE[\"jd_snapshot\"]\n",
    "    js[\"title\"] = obj.get(\"title\") or js.get(\"title\") or None\n",
    "\n",
    "    def _pull_tokens(items, key=\"token\"):\n",
    "        out = []\n",
    "        evid = {}\n",
    "        for it in items or []:\n",
    "            tok = (it.get(key) or \"\").strip().lower()\n",
    "            ev  = (it.get(\"evidence\") or \"\").strip()\n",
    "            if tok:\n",
    "                out.append(tok)\n",
    "                evid[tok] = ev\n",
    "        return list(dict.fromkeys(out)), evid\n",
    "\n",
    "    must_list, must_ev = _pull_tokens(obj.get(\"must_haves\") or [])\n",
    "    req_list,  req_ev  = _pull_tokens(obj.get(\"required\") or [])\n",
    "    pref_list, pref_ev = _pull_tokens(obj.get(\"preferred\") or [])\n",
    "    resp_list, resp_ev = [], {}\n",
    "    for it in obj.get(\"responsibilities\") or []:\n",
    "        phr = (it.get(\"phrase\") or \"\").strip().lower()\n",
    "        ev  = (it.get(\"evidence\") or \"\").strip()\n",
    "        if phr:\n",
    "            resp_list.append(phr); resp_ev[phr] = ev\n",
    "\n",
    "    js[\"must_haves\"] = must_list\n",
    "    js[\"required\"]   = req_list\n",
    "    js[\"preferred\"]  = pref_list\n",
    "    js[\"responsibilities\"] = resp_list\n",
    "    js[\"evidence\"] = {\"must\": must_ev, \"req\": req_ev, \"pref\": pref_ev, \"resp\": resp_ev}\n",
    "\n",
    "    hg_in = obj.get(\"hard_gates\") or {}\n",
    "    def _gate_val(key, default=None):\n",
    "        g = hg_in.get(key) or {}\n",
    "        return (g.get(\"value\") if isinstance(g, dict) else None) if g else default\n",
    "    def _gate_ev(key):\n",
    "        g = hg_in.get(key) or {}\n",
    "        return (g.get(\"evidence\") or \"\") if isinstance(g, dict) else \"\"\n",
    "\n",
    "    js[\"hard_gates\"] = {\n",
    "        \"degree_required\": _gate_val(\"degree_required\", False),\n",
    "        \"min_years\": _gate_val(\"min_years\", None),\n",
    "        \"license\": [x.get(\"token\",\"\").lower() for x in (hg_in.get(\"license\") or []) if x.get(\"token\")],\n",
    "        \"work_auth\": _gate_val(\"work_auth\", None),\n",
    "        \"clearance\": _gate_val(\"clearance\", None),\n",
    "        \"location_mode\": _gate_val(\"location_mode\", None),\n",
    "        \"onsite_city\": _gate_val(\"onsite_city\", None),\n",
    "        \"shift\": _gate_val(\"shift\", None),\n",
    "        \"travel\": _gate_val(\"travel\", None),\n",
    "    }\n",
    "    js[\"hard_gate_evidence\"] = {\n",
    "        k: _gate_ev(k) for k in [\n",
    "            \"degree_required\",\"min_years\",\"license\",\"work_auth\",\n",
    "            \"clearance\",\"location_mode\",\"onsite_city\",\"shift\",\"travel\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "        with open(STATE[\"artifacts\"][\"paths\"][\"jd_snapshot_json\"], \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(STATE[\"jd_snapshot\"], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"[ok] JD snapshot (strict) ready; no expansions were allowed.\")\n",
    "\n",
    "# ---------------- 2) Select chunks within budget (from Cell 3 hybrid retrieval) ----------------\n",
    "opts = STATE[\"options\"]\n",
    "sel_ids = list(STATE[\"faiss\"].get(\"topk_ids\") or [])\n",
    "if not sel_ids:\n",
    "    sel_ids = [c[\"id\"] for c in STATE[\"chunks\"][:opts[\"extract_max_chunks\"]]]\n",
    "sel_ids = sel_ids[:opts[\"extract_max_chunks\"]]\n",
    "\n",
    "id_to_chunk = {c[\"id\"]: c for c in STATE[\"chunks\"]}\n",
    "sel_chunks = [id_to_chunk[i] for i in sel_ids if i in id_to_chunk]\n",
    "\n",
    "# Leave room for consolidation if possible\n",
    "remaining_llm = max(0, opts[\"llm_budget_calls\"] - STATE[\"_llm_calls\"])\n",
    "reserve_for_consolidation = 1 if remaining_llm > 1 else 0\n",
    "allowed = max(0, min(len(sel_chunks), remaining_llm - reserve_for_consolidation))\n",
    "if allowed < len(sel_chunks):\n",
    "    sel_chunks = sel_chunks[:allowed]\n",
    "print(f\"[ok] Planning extraction for {len(sel_chunks)} chunk(s) within budget (used={STATE['_llm_calls']}/{opts['llm_budget_calls']}).\")\n",
    "\n",
    "# ---------------- 3) Per-chunk AI extraction with EVIDENCE (LLM; strict; one chunk per call) ----------------\n",
    "EXTRACT_PROMPT_STRICT = r\"\"\"\n",
    "You are extracting structured resume data from ONE chunk. \n",
    "RULES:\n",
    "- Return ONLY items that are EXPLICITLY present in this chunk. Do NOT infer or expand.\n",
    "- For every field, include an \"evidence\" snippet (<=160 chars) copied from this chunk.\n",
    "- Keep tokens lowercase and atomic where applicable.\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{\n",
    "  \"contacts\": { \"name\": null, \"email\": null, \"phone\": null, \"links\": [\"urls\"], \"evidence\": {\"name\":\"\", \"email\":\"\", \"phone\":\"\", \"links\":[\"...\"]} },\n",
    "  \"education\": [ { \"degree\": \"\", \"field\": \"\", \"institution\": \"\", \"start\": null, \"end\": null, \"location\": null, \"evidence\": \"\" } ],\n",
    "  \"experience\": [ { \"title\": \"\", \"company\": \"\", \"location\": null, \"start\": null, \"end\": null, \"highlights\": [\"...\"], \"evidence\": \"\" } ],\n",
    "  \"projects\": [ { \"name\": \"\", \"tech\": [\"tokens\"], \"impact\": null, \"links\": [\"urls\"], \"evidence\": \"\" } ],\n",
    "  \"skills\": [ { \"token\": \"\", \"evidence\": \"\" } ],\n",
    "  \"certifications\": [ { \"token\": \"\", \"evidence\": \"\" } ],\n",
    "  \"awards\": [ { \"token\": \"\", \"evidence\": \"\" } ],\n",
    "  \"locations\": [ { \"token\": \"\", \"evidence\": \"\" } ]\n",
    "}\n",
    "\n",
    "Chunk ID: {chunk_id}\n",
    "Chunk:\n",
    "---\n",
    "{chunk_text}\n",
    "---\n",
    "\"\"\"\n",
    "EXTRACT_PROMPT_STRICT = _escape_braces_keep_vars(EXTRACT_PROMPT_STRICT, [\"chunk_id\",\"chunk_text\"])\n",
    "\n",
    "entities_by_chunk: Dict[str, Dict[str, Any]] = {}\n",
    "if sel_chunks:\n",
    "    extract_chain = ChatPromptTemplate.from_template(EXTRACT_PROMPT_STRICT) | llm\n",
    "    for ch in sel_chunks:\n",
    "        if not _budget_ok(1): break\n",
    "        out = extract_chain.invoke({\"chunk_id\": ch[\"id\"], \"chunk_text\": ch[\"text\"]})\n",
    "        _bump(1)\n",
    "        try:\n",
    "            obj = _json_loose(getattr(out, \"content\", str(out)))\n",
    "        except Exception:\n",
    "            obj = {}\n",
    "        entities_by_chunk[ch[\"id\"]] = obj\n",
    "\n",
    "if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "    with open(Path(STATE[\"artifacts\"][\"base_dir\"]) / \"extract_pass_raw.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(entities_by_chunk, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ---------------- 4) CONSOLIDATION (1 LLM call): dedupe & unify synonyms ONLY with evidence ----------------\n",
    "CONSOLIDATE_PROMPT = r\"\"\"\n",
    "You are merging multiple chunk-level JSON extractions of a single resume.\n",
    "RULES:\n",
    "- Deduplicate across chunks.\n",
    "- Unify obvious synonyms ONLY if each synonym has evidence text somewhere in the inputs (e.g., \"oop\",\"o.o.p\",\"object oriented programming\" ‚Üí canonical \"object oriented programming\").\n",
    "- If there is no evidence for an item, DROP it.\n",
    "- Keep for each final item an array of \"evidence\" snippets (from the inputs).\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{\n",
    "  \"contacts\": { \"name\": null, \"email\": null, \"phone\": null, \"links\": [\"urls\"] },\n",
    "  \"education\": [ { \"degree\": \"\", \"field\": \"\", \"institution\": \"\", \"start\": null, \"end\": null, \"location\": null, \"evidence\": [\"...\"] } ],\n",
    "  \"experience\": [ { \"title\": \"\", \"company\": \"\", \"location\": null, \"start\": null, \"end\": null, \"highlights\": [\"...\"], \"evidence\": [\"...\"] } ],\n",
    "  \"projects\": [ { \"name\": \"\", \"tech\": [\"tokens\"], \"impact\": null, \"links\": [\"urls\"], \"evidence\": [\"...\"] } ],\n",
    "  \"skills\": [ { \"canonical\": \"\", \"aliases\": [\"...\"], \"evidence\": [\"...\"] } ],\n",
    "  \"certifications\": [ { \"canonical\": \"\", \"aliases\": [\"...\"], \"evidence\": [\"...\"] } ],\n",
    "  \"awards\": [ { \"canonical\": \"\", \"evidence\": [\"...\"] } ],\n",
    "  \"locations\": [ { \"canonical\": \"\", \"evidence\": [\"...\"] } ]\n",
    "}\n",
    "\n",
    "Inputs:\n",
    "---\n",
    "{chunk_json}\n",
    "---\n",
    "\"\"\"\n",
    "CONSOLIDATE_PROMPT = _escape_braces_keep_vars(CONSOLIDATE_PROMPT, [\"chunk_json\"])\n",
    "\n",
    "merged: Dict[str, Any] = {}\n",
    "if entities_by_chunk and _budget_ok(1):\n",
    "    cons_chain = ChatPromptTemplate.from_template(CONSOLIDATE_PROMPT) | llm\n",
    "    payload = json.dumps(entities_by_chunk, ensure_ascii=False)\n",
    "    cons_raw = cons_chain.invoke({\"chunk_json\": payload})\n",
    "    _bump(1)\n",
    "    merged = _json_loose(getattr(cons_raw, \"content\", str(cons_raw)))\n",
    "else:\n",
    "    merged = {}\n",
    "\n",
    "# ---------------- 5) Write consolidated into STATE ----------------\n",
    "def _uniq_preserve(xs):\n",
    "    seen=set(); out=[]\n",
    "    for x in xs:\n",
    "        k = json.dumps(x, sort_keys=True) if isinstance(x,(dict,list)) else str(x).lower()\n",
    "        if k not in seen:\n",
    "            seen.add(k); out.append(x)\n",
    "    return out\n",
    "\n",
    "# Contacts\n",
    "if isinstance(merged.get(\"contacts\"), dict):\n",
    "    c = merged[\"contacts\"]\n",
    "    if c.get(\"name\"):  STATE[\"contacts\"][\"name\"]  = STATE[\"contacts\"].get(\"name\")  or c[\"name\"]\n",
    "    if c.get(\"email\"): STATE[\"contacts\"][\"email\"] = STATE[\"contacts\"].get(\"email\") or c[\"email\"]\n",
    "    if c.get(\"phone\"): STATE[\"contacts\"][\"phone\"] = STATE[\"contacts\"].get(\"phone\") or c[\"phone\"]\n",
    "    if isinstance(c.get(\"links\"), list):\n",
    "        for u in c[\"links\"]:\n",
    "            if \"linkedin.com\" in u and not STATE[\"contacts\"][\"links\"].get(\"linkedin\"): STATE[\"contacts\"][\"links\"][\"linkedin\"] = u\n",
    "            elif \"github.com\" in u and not STATE[\"contacts\"][\"links\"].get(\"github\"):   STATE[\"contacts\"][\"links\"][\"github\"] = u\n",
    "\n",
    "# Lists\n",
    "for key in [\"education\",\"timeline\",\"projects\",\"skills\",\"certs\",\"awards\",\"locations\"]:\n",
    "    STATE[key] = []\n",
    "\n",
    "def _extend(dst_key: str, seq: List[Dict[str, Any]]):\n",
    "    for it in seq or []:\n",
    "        STATE[dst_key].append(dict(it))\n",
    "\n",
    "_extend(\"education\", merged.get(\"education\") or [])\n",
    "_extend(\"timeline\",  merged.get(\"experience\") or [])\n",
    "_extend(\"projects\",  merged.get(\"projects\") or [])\n",
    "\n",
    "for s in merged.get(\"skills\") or []:\n",
    "    STATE[\"skills\"].append({\n",
    "        \"name\": (s.get(\"canonical\") or \"\").lower(),\n",
    "        \"aliases\": [a.lower() for a in (s.get(\"aliases\") or [])],\n",
    "        \"evidence\": s.get(\"evidence\") or [],\n",
    "        \"chunk_ids\": [],\n",
    "    })\n",
    "for c in merged.get(\"certifications\") or []:\n",
    "    STATE[\"certs\"].append({\"name\": (c.get(\"canonical\") or \"\").lower(), \"evidence\": c.get(\"evidence\") or []})\n",
    "for a in merged.get(\"awards\") or []:\n",
    "    STATE[\"awards\"].append({\"name\": (a.get(\"canonical\") or \"\").lower(), \"evidence\": a.get(\"evidence\") or []})\n",
    "for l in merged.get(\"locations\") or []:\n",
    "    STATE[\"locations\"].append((l.get(\"canonical\") or \"\").lower())\n",
    "\n",
    "# De-dup simple lists\n",
    "STATE[\"education\"] = _uniq_preserve(STATE[\"education\"])\n",
    "STATE[\"timeline\"]  = _uniq_preserve(STATE[\"timeline\"])\n",
    "STATE[\"projects\"]  = _uniq_preserve(STATE[\"projects\"])\n",
    "STATE[\"skills\"]    = _uniq_preserve(STATE[\"skills\"])\n",
    "STATE[\"certs\"]     = _uniq_preserve(STATE[\"certs\"])\n",
    "STATE[\"awards\"]    = _uniq_preserve(STATE[\"awards\"])\n",
    "STATE[\"locations\"] = _uniq_preserve(STATE[\"locations\"])\n",
    "\n",
    "# ---------------- 6) High-level: years of experience ----------------\n",
    "total_months = 0\n",
    "now = _now()\n",
    "for r in STATE[\"timeline\"]:\n",
    "    st = _parse_date_soft(r.get(\"start\"))\n",
    "    en = _parse_date_soft(r.get(\"end\")) or now\n",
    "    if st:\n",
    "        total_months += _months_between(st, en)\n",
    "STATE[\"high_level\"][\"years_experience\"] = round(total_months / 12.0, 2) if total_months else None\n",
    "\n",
    "# ---------------- 7) Canonical resume terms (aliases + semantic clustering over observed terms) ----------------\n",
    "alias = STATE[\"canon\"][\"skill_alias\"]\n",
    "raw_terms: List[str] = []\n",
    "for s in STATE[\"skills\"]:\n",
    "    if s.get(\"name\"): raw_terms.append(s[\"name\"])\n",
    "    for a in s.get(\"aliases\") or []: raw_terms.append(a)\n",
    "for p in STATE[\"projects\"]:\n",
    "    for t in (p.get(\"tech\") or []): raw_terms.append(str(t).lower())\n",
    "for r in STATE[\"timeline\"]:\n",
    "    if r.get(\"title\"): raw_terms.append(str(r[\"title\"]).lower())\n",
    "    for h in (r.get(\"highlights\") or []): raw_terms.append(str(h).lower())\n",
    "for c in STATE[\"certs\"]:\n",
    "    if c.get(\"name\"): raw_terms.append(str(c[\"name\"]).lower())\n",
    "\n",
    "norm_terms = []\n",
    "for tok in raw_terms:\n",
    "    t = tok.strip().lower()\n",
    "    t = alias.get(t, t)\n",
    "    norm_terms.append(t)\n",
    "unique_terms = list(dict.fromkeys([t for t in norm_terms if t]))\n",
    "\n",
    "# semantic clustering (observed terms only; cosine‚â•0.82)\n",
    "term_vecs = embed_texts(unique_terms, batch_size=STATE[\"options\"][\"embed_batch_size\"])\n",
    "canons: List[Dict[str, Any]] = []\n",
    "def _find_bucket(vec):\n",
    "    best_i, best_sc = None, -1.0\n",
    "    for i, c in enumerate(canons):\n",
    "        sc = cosine_sim(vec, c[\"vec\"])\n",
    "        if sc > best_sc:\n",
    "            best_sc, best_i = sc, i\n",
    "    return best_i, best_sc\n",
    "THRESH_CANON = 0.82\n",
    "for term, vec in zip(unique_terms, term_vecs):\n",
    "    if not canons:\n",
    "        canons.append({\"name\": term, \"vec\": vec, \"members\": {term}})\n",
    "        continue\n",
    "    bi, sc = _find_bucket(vec)\n",
    "    if sc >= THRESH_CANON:\n",
    "        canons[bi][\"members\"].add(term)\n",
    "    else:\n",
    "        canons.append({\"name\": term, \"vec\": vec, \"members\": {term}})\n",
    "\n",
    "TERM_TO_CANON: Dict[str, str] = {}\n",
    "for c in canons:\n",
    "    label = min(c[\"members\"], key=len)\n",
    "    for m in c[\"members\"]:\n",
    "        TERM_TO_CANON[m] = label\n",
    "RESUME_CANON_TERMS = sorted(set(TERM_TO_CANON.get(t, t) for t in unique_terms))\n",
    "STATE[\"canon\"][\"normalized_skills\"] = RESUME_CANON_TERMS\n",
    "\n",
    "# ---------------- 8) JD tokens (NO expansions) ----------------\n",
    "jd = STATE[\"jd_snapshot\"]\n",
    "JD_MUST = jd.get(\"must_haves\", []) or []\n",
    "JD_REQ  = jd.get(\"required\", []) or []\n",
    "JD_PREF = jd.get(\"preferred\", []) or []\n",
    "JD_RESP = jd.get(\"responsibilities\", []) or []\n",
    "\n",
    "# ---------------- 9) Alignment (semantic, batched) ----------------\n",
    "def _best_match(token: str, candidate_terms: List[str]) -> Dict[str, Any]:\n",
    "    if not token or not candidate_terms:\n",
    "        return {\"match\": None, \"score\": 0.0}\n",
    "    pairs = [token] + candidate_terms\n",
    "    vecs = embed_texts(pairs, batch_size=STATE[\"options\"][\"embed_batch_size\"])\n",
    "    tv = vecs[0]; cvs = vecs[1:]\n",
    "    best_sc = -1.0; best_term = None\n",
    "    for tm, vv in zip(candidate_terms, cvs):\n",
    "        sc = cosine_sim(tv, vv)\n",
    "        if sc > best_sc:\n",
    "            best_sc = sc; best_term = tm\n",
    "    return {\"match\": best_term, \"score\": float(best_sc)}\n",
    "\n",
    "def _align_list(tokens: List[str]) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    STRONG = STATE[\"options\"][\"bert_strong\"]\n",
    "    PART   = STATE[\"options\"][\"bert_partial\"]\n",
    "    for t in tokens:\n",
    "        bm = _best_match(t, RESUME_CANON_TERMS)\n",
    "        status = \"missing\"\n",
    "        if bm[\"score\"] >= STRONG: status = \"present_strong\"\n",
    "        elif bm[\"score\"] >= PART: status = \"present_partial\"\n",
    "        out.append({\"name\": t, \"status\": status, \"evidence\": bm[\"match\"], \"similarity\": round(bm[\"score\"], 3)})\n",
    "    return out\n",
    "\n",
    "STATE[\"jd_alignment\"][\"must_have\"] = _align_list(JD_MUST)\n",
    "STATE[\"jd_alignment\"][\"required\"]  = _align_list(JD_REQ)\n",
    "STATE[\"jd_alignment\"][\"preferred\"] = _align_list(JD_PREF)\n",
    "\n",
    "# responsibilities coverage via semantic best-hit\n",
    "resp_cover = 0.0\n",
    "highlights: List[str] = []\n",
    "for r in STATE[\"timeline\"]:\n",
    "    for h in (r.get(\"highlights\") or []):\n",
    "        highlights.append(h)\n",
    "for p in STATE[\"projects\"]:\n",
    "    if p.get(\"impact\"): highlights.append(p[\"impact\"])\n",
    "if JD_RESP and highlights:\n",
    "    rv = embed_texts(JD_RESP, batch_size=STATE[\"options\"][\"embed_batch_size\"])\n",
    "    hv = embed_texts(highlights[:50], batch_size=STATE[\"options\"][\"embed_batch_size\"])  # cap 50 for efficiency\n",
    "    PART = STATE[\"options\"][\"bert_partial\"]\n",
    "    hits = 0\n",
    "    for rvec in rv:\n",
    "        best = max(cosine_sim(rvec, hvec) for hvec in hv) if hv else 0.0\n",
    "        hits += 1 if best >= PART else 0\n",
    "    resp_cover = hits / max(1, len(JD_RESP))\n",
    "STATE[\"jd_alignment\"][\"responsibilities\"] = {\"coverage\": round(resp_cover, 3), \"count\": len(JD_RESP)}\n",
    "\n",
    "# role & project relevance vs a single JD vector\n",
    "jd_vec = embed_query(\" | \".join(JD_REQ + JD_RESP)[:4000])\n",
    "\n",
    "def _recency_weight(months: Optional[int]) -> float:\n",
    "    if months is None: return 0.7\n",
    "    if months <= 6: return 1.0\n",
    "    if months <= 24: return 0.5 + 0.5 * (24 - months) / 18.0\n",
    "    if months <= 60: return 0.3 + 0.2 * (60 - months) / 36.0\n",
    "    return 0.3\n",
    "\n",
    "now = _now()\n",
    "for r in STATE[\"timeline\"]:\n",
    "    # compute recency months if missing\n",
    "    end_dt = _parse_date_soft(r.get(\"end\")) or now\n",
    "    r[\"recency_months\"] = max(0, (now.year - end_dt.year) * 12 + (now.month - end_dt.month))\n",
    "    blob = \" \".join([_clip(r.get(\"title\")), _clip(r.get(\"company\"))] + [ _clip(h) for h in (r.get(\"highlights\") or []) ])\n",
    "    rv = embed_query(blob)\n",
    "    r[\"jd_relevance\"] = float(cosine_sim(rv, jd_vec))\n",
    "\n",
    "for p in STATE[\"projects\"]:\n",
    "    blob = \" \".join([_clip(p.get(\"name\"))] + [ _clip(t) for t in (p.get(\"tech\") or []) ] + ([ _clip(p.get(\"impact\")) ] if p.get(\"impact\") else []))\n",
    "    pv = embed_query(blob)\n",
    "    p[\"jd_relevance\"] = float(cosine_sim(pv, jd_vec))\n",
    "\n",
    "print(\"[ok] Strict extraction + consolidation + semantic alignment complete.\")\n",
    "print(f\"  - roles: {len(STATE['timeline'])}, projects: {len(STATE['projects'])}, skills (canonical observed): {len(STATE['canon']['normalized_skills'])}\")\n",
    "print(f\"  - alignment: must_have={len(STATE['jd_alignment']['must_have'])}, req={len(STATE['jd_alignment']['required'])}, pref={len(STATE['jd_alignment']['preferred'])}\")\n",
    "print(f\"  - responsibilities coverage‚âà{int(STATE['jd_alignment']['responsibilities']['coverage']*100)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef0e78ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Final score: 53/100  | selected=False\n",
      "[ok] Breakdown: {\n",
      "  \"must_have_coverage\": 30.0,\n",
      "  \"required_coverage\": 0.0,\n",
      "  \"preferred_coverage\": 8.0,\n",
      "  \"role_alignment\": 0.0,\n",
      "  \"project_alignment\": 2.73,\n",
      "  \"evidence_depth\": 0.75,\n",
      "  \"seniority_fit\": 8.0,\n",
      "  \"responsibility_overlap\": 4.0,\n",
      "  \"soft_penalties\": {\n",
      "    \"missing_many_must_haves\": 0,\n",
      "    \"degree_missing_penalty\": 0,\n",
      "    \"zero_metrics_penalty\": 0,\n",
      "    \"location_penalty\": 0\n",
      "  },\n",
      "  \"hard_gate_cap\": null\n",
      "}\n",
      "[ok] Reasons:\n",
      "  - Must-have coverage: 100% ; Required: 0% ; Preferred: 100%\n",
      "  - Responsibilities overlap‚âà100% ; Evidence signals=1.\n",
      "  - Role alignment‚âà0% ; Project alignment‚âà34%.\n",
      "[ok] Strong matches: algorithms, c++, cmake, data structures, exception handling, file handling, git, memory management, multithreading, object-oriented programming, sdlc, stl\n",
      "[ok] Gaps: ‚Äî\n",
      "[ok] Risk flags: Years of experience could not be inferred\n",
      "[ok] Saved ‚Üí tmp\\52d59f5aaedc\\final.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 5: Scoring ‚Üí Gates ‚Üí Final Decision ‚Üí Persist (Gemini-only embeddings; no extra LLM calls) ====\n",
    "# Produces a 0‚Äì100 score, selected flag, detailed coverage/gaps/reasons, and persists final JSON.\n",
    "\n",
    "import json, re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "opts = STATE[\"options\"]\n",
    "weights = opts[\"weights\"]\n",
    "\n",
    "def _now():\n",
    "    return datetime.utcnow()\n",
    "\n",
    "def _parse_date_soft(s: Optional[str]) -> Optional[datetime]:\n",
    "    if not s: return None\n",
    "    tl = str(s).strip().lower()\n",
    "    if any(k in tl for k in [\"present\", \"current\", \"now\"]): return _now()\n",
    "    from dateutil import parser\n",
    "    try:\n",
    "        dt = parser.parse(tl, default=datetime(2000,1,1), fuzzy=True)\n",
    "        if 1900 <= dt.year <= 2100:\n",
    "            return datetime(dt.year, dt.month if dt.month else 1, 1)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r\"(20\\d{2}|19\\d{2})\", tl)\n",
    "    if m: return datetime(int(m.group(1)), 1, 1)\n",
    "    return None\n",
    "\n",
    "def _months_between(a: Optional[datetime], b: Optional[datetime]) -> int:\n",
    "    if not a or not b: return 0\n",
    "    return max(0, (b.year - a.year) * 12 + (b.month - a.month))\n",
    "\n",
    "def _recency_weight(months: Optional[int]) -> float:\n",
    "    if months is None: return 0.7\n",
    "    if months <= 6: return 1.0\n",
    "    if months <= 24: return 0.5 + 0.5 * (24 - months) / 18.0\n",
    "    if months <= 60: return 0.3 + 0.2 * (60 - months) / 36.0\n",
    "    return 0.3\n",
    "\n",
    "# ---------- 1) Evidence depth (metrics/impact signals) ----------\n",
    "highlights: List[str] = []\n",
    "for r in STATE[\"timeline\"]:\n",
    "    highlights.extend(r.get(\"highlights\") or [])\n",
    "for p in STATE[\"projects\"]:\n",
    "    if p.get(\"impact\"): highlights.append(p[\"impact\"])\n",
    "\n",
    "metric_pat = re.compile(r\"\\b\\d+(?:\\.\\d+)?%|\\b\\d+(?:\\.\\d+)?(?:k|m|b)\\b|\\b\\d{2,}\\b|\\$\\s?\\d[\\d,]*(?:\\.\\d+)?\", re.I)\n",
    "metric_count = sum(len(metric_pat.findall(h or \"\")) for h in highlights)\n",
    "# Smooth to [0,1] with gentle saturation: ~8+ metrics => 1.0\n",
    "evidence_depth = min(1.0, metric_count / 8.0)\n",
    "\n",
    "# ---------- 2) Seniority fit ----------\n",
    "jd = STATE[\"jd_snapshot\"]\n",
    "req_years = None\n",
    "try:\n",
    "    req_years = int(jd.get(\"hard_gates\", {}).get(\"min_years\") or 0) or None\n",
    "except Exception:\n",
    "    req_years = None\n",
    "\n",
    "yrs = STATE[\"high_level\"].get(\"years_experience\")\n",
    "seniority_fit = 1.0\n",
    "if yrs is not None and req_years is not None:\n",
    "    # Treat 70% of JD years as near-fit for friendliness\n",
    "    denom = max(1.0, 0.7 * req_years)\n",
    "    seniority_fit = max(0.0, min(1.0, float(yrs) / denom))\n",
    "\n",
    "# ---------- 3) Responsibilities overlap (already computed in Cell 4) ----------\n",
    "resp_cover = float(STATE[\"jd_alignment\"].get(\"responsibilities\", {}).get(\"coverage\", 0.0))\n",
    "\n",
    "# ---------- 4) Role & Project alignment ----------\n",
    "# Ensure recency_months & tenure months computed, and combine with jd_relevance\n",
    "now = _now()\n",
    "role_scores = []\n",
    "for r in STATE[\"timeline\"]:\n",
    "    st = _parse_date_soft(r.get(\"start\"))\n",
    "    en = _parse_date_soft(r.get(\"end\")) or now\n",
    "    tenure_mo = _months_between(st, en) if st else 0\n",
    "    r[\"tenure_months\"] = tenure_mo\n",
    "    rec_w = _recency_weight(r.get(\"recency_months\", _months_between(en, now)))\n",
    "    ten_w = min(1.0, (tenure_mo or 0) / 9.0)  # 9+ months ~ full credit\n",
    "    rel = float(r.get(\"jd_relevance\") or 0.0)  # 0..1 from Cell 4\n",
    "    role_scores.append(rel * rec_w * ten_w)\n",
    "\n",
    "role_alignment = sum(role_scores) / max(1, len(role_scores)) if role_scores else 0.0\n",
    "\n",
    "proj_scores = [float(p.get(\"jd_relevance\") or 0.0) for p in STATE[\"projects\"]]\n",
    "project_alignment = sum(proj_scores) / max(1, len(proj_scores)) if proj_scores else 0.0\n",
    "\n",
    "# ---------- 5) Coverage (must-have / required / preferred) ----------\n",
    "def _coverage(items: List[Dict[str, Any]]) -> float:\n",
    "    if not items: return 0.0\n",
    "    total = len(items)\n",
    "    strong = sum(1 for x in items if x.get(\"status\") == \"present_strong\")\n",
    "    partial = sum(1 for x in items if x.get(\"status\") == \"present_partial\")\n",
    "    # partial credit weighting\n",
    "    return (strong + 0.6 * partial) / max(1, total)\n",
    "\n",
    "must_cov = _coverage(STATE[\"jd_alignment\"].get(\"must_have\", []))\n",
    "req_cov  = _coverage(STATE[\"jd_alignment\"].get(\"required\", []))\n",
    "pref_cov = _coverage(STATE[\"jd_alignment\"].get(\"preferred\", []))\n",
    "\n",
    "# Small contextual boosts\n",
    "if role_alignment >= 0.6: req_cov = min(1.0, req_cov + 0.05)\n",
    "if project_alignment >= 0.6: pref_cov = min(1.0, pref_cov + 0.04)\n",
    "\n",
    "# ---------- 6) Hard gates evaluation ----------\n",
    "failed_gates: List[str] = []\n",
    "gate_notes: List[str] = []\n",
    "hg = jd.get(\"hard_gates\", {}) or {}\n",
    "\n",
    "# degree gate\n",
    "degree_required = bool(hg.get(\"degree_required\"))\n",
    "has_degree = any((e.get(\"degree\") or e.get(\"field\")) for e in STATE[\"education\"])\n",
    "if degree_required and not has_degree:\n",
    "    failed_gates.append(\"degree_required\")\n",
    "    gate_notes.append(\"JD requires a degree; none detected in education section\")\n",
    "\n",
    "# min years gate (hard gate; we already compute seniority_fit but also check)\n",
    "if req_years is not None and (yrs is None or yrs + 0.01 < 0.6 * req_years):  # allow some leeway\n",
    "    failed_gates.append(\"min_years_experience\")\n",
    "    gate_notes.append(f\"Requires ~{req_years}y; inferred ~{yrs or 0}y\")\n",
    "\n",
    "# license gate (CPA/RN/PE/PMP/etc.)\n",
    "licenses_needed = [str(x).lower() for x in (hg.get(\"license\") or [])]\n",
    "if licenses_needed:\n",
    "    resume_lics = [str(c.get(\"name\",\"\")).lower() for c in STATE[\"certs\"]]\n",
    "    lic_missing = [ln for ln in licenses_needed if all(ln not in rl for rl in resume_lics)]\n",
    "    if lic_missing:\n",
    "        failed_gates.append(\"license_required\")\n",
    "        gate_notes.append(f\"Missing license(s): {', '.join(lic_missing)}\")\n",
    "\n",
    "# work authorization (very light; text scan)\n",
    "if hg.get(\"work_auth\"):\n",
    "    wanted = str(hg.get(\"work_auth\")).lower()\n",
    "    resume_text_lower = (STATE[\"raw\"].get(\"resume_text\") or \"\").lower()\n",
    "    if wanted not in resume_text_lower:\n",
    "        failed_gates.append(\"work_authorization\")\n",
    "        gate_notes.append(f\"Work authorization required: {wanted}\")\n",
    "\n",
    "# clearance\n",
    "if hg.get(\"clearance\"):\n",
    "    need = str(hg.get(\"clearance\")).lower()\n",
    "    have = (STATE[\"raw\"].get(\"resume_text\") or \"\").lower()\n",
    "    if need not in have:\n",
    "        failed_gates.append(\"security_clearance\")\n",
    "        gate_notes.append(f\"Security clearance required: {need}\")\n",
    "\n",
    "# location mode (onsite/hybrid/remote) ‚Äî treat mismatch as soft penalty unless explicitly \"onsite only\"\n",
    "location_soft_penalty = 0\n",
    "if hg.get(\"location_mode\") == \"onsite\":\n",
    "    city = (hg.get(\"onsite_city\") or \"\").lower()\n",
    "    # if resume locations don't mention the city, flag soft penalty\n",
    "    resume_locs = [str(x).lower() for x in STATE.get(\"locations\") or []]\n",
    "    if city and all(city not in l for l in resume_locs):\n",
    "        location_soft_penalty = 5  # soft, not a hard fail\n",
    "        gate_notes.append(f\"Onsite location preference '{city}' not evidenced in resume\")\n",
    "\n",
    "# shift/travel ‚Äî informational; turn into soft penalties if extreme (optional)\n",
    "shift_note = hg.get(\"shift\")\n",
    "travel_note = hg.get(\"travel\")\n",
    "if shift_note: gate_notes.append(f\"Shift requirement: {shift_note}\")\n",
    "if travel_note: gate_notes.append(f\"Travel requirement: {travel_note}\")\n",
    "\n",
    "STATE[\"gates\"][\"failed\"] = failed_gates\n",
    "STATE[\"gates\"][\"notes\"] = gate_notes\n",
    "\n",
    "# ---------- 7) Score computation ----------\n",
    "score = (\n",
    "    weights[\"must_have_coverage\"]      * must_cov +\n",
    "    weights[\"required_coverage\"]       * req_cov +\n",
    "    weights[\"preferred_coverage\"]      * pref_cov +\n",
    "    weights[\"role_alignment\"]          * role_alignment +\n",
    "    weights[\"project_alignment\"]       * project_alignment +\n",
    "    weights[\"evidence_depth\"]          * evidence_depth +\n",
    "    weights[\"seniority_fit\"]           * seniority_fit +\n",
    "    weights[\"responsibility_overlap\"]  * resp_cover\n",
    ")\n",
    "\n",
    "# Soft penalties\n",
    "missing_must = [x[\"name\"] for x in STATE[\"jd_alignment\"].get(\"must_have\", []) if x[\"status\"] == \"missing\"]\n",
    "if len(missing_must) > 4:\n",
    "    score -= 5  # too many missing must-haves\n",
    "if degree_required and not has_degree:\n",
    "    score -= 3  # extra nudge if JD explicitly asked for a degree\n",
    "if metric_count == 0:\n",
    "    score -= 3  # no measurable outcomes\n",
    "score -= location_soft_penalty\n",
    "\n",
    "# Hard gate cap\n",
    "if failed_gates:\n",
    "    score = min(score, float(opts.get(\"gate_hard_cap\", 59)))\n",
    "\n",
    "# Clamp and round\n",
    "score_100 = int(round(max(0.0, min(100.0, score))))\n",
    "\n",
    "# Selection rule\n",
    "selected = (score_100 >= 70) and (len(failed_gates) == 0)\n",
    "\n",
    "# ---------- 8) Reasons / Strong matches / Gaps / Risks ----------\n",
    "def _names_with_status(items: List[Dict[str, Any]], status: str) -> List[str]:\n",
    "    return [x[\"name\"] for x in items if x.get(\"status\") == status]\n",
    "\n",
    "strong_from_must = _names_with_status(STATE[\"jd_alignment\"].get(\"must_have\", []), \"present_strong\")\n",
    "strong_from_req  = _names_with_status(STATE[\"jd_alignment\"].get(\"required\", []), \"present_strong\")\n",
    "strong_matches = sorted(set(strong_from_must + strong_from_req))[:20]\n",
    "\n",
    "gaps = [x[\"name\"] for x in STATE[\"jd_alignment\"].get(\"must_have\", []) if x[\"status\"] == \"missing\"]\n",
    "gaps += [x[\"name\"] for x in STATE[\"jd_alignment\"].get(\"required\", []) if x[\"status\"] == \"missing\"]\n",
    "gaps = sorted(set(gaps))[:20]\n",
    "\n",
    "reasons: List[str] = []\n",
    "reasons.append(f\"Must-have coverage: {int(round(100*must_cov))}% ; Required: {int(round(100*req_cov))}% ; Preferred: {int(round(100*pref_cov))}%\")\n",
    "if yrs is not None:\n",
    "    if req_years is not None:\n",
    "        reasons.append(f\"Experience: {yrs} yrs vs JD ~{req_years} yrs (fit‚âà{int(round(100*seniority_fit))}%).\")\n",
    "    else:\n",
    "        reasons.append(f\"Experience: {yrs} yrs (JD years not specified).\")\n",
    "reasons.append(f\"Responsibilities overlap‚âà{int(round(100*resp_cover))}% ; Evidence signals={metric_count}.\")\n",
    "reasons.append(f\"Role alignment‚âà{int(round(100*role_alignment))}% ; Project alignment‚âà{int(round(100*project_alignment))}%.\")\n",
    "\n",
    "risk_flags: List[str] = []\n",
    "if failed_gates:\n",
    "    risk_flags.append(\"Hard gates failed: \" + \", \".join(failed_gates))\n",
    "if not STATE[\"contacts\"].get(\"email\"):\n",
    "    risk_flags.append(\"No email detected\")\n",
    "if yrs is None:\n",
    "    risk_flags.append(\"Years of experience could not be inferred\")\n",
    "if metric_count == 0:\n",
    "    risk_flags.append(\"No quantifiable achievements detected\")\n",
    "if location_soft_penalty:\n",
    "    risk_flags.append(\"Onsite location not evidenced\")\n",
    "\n",
    "# ---------- 9) Persist final ----------\n",
    "STATE[\"final\"] = {\n",
    "    \"score_100\": score_100,\n",
    "    \"selected\": bool(selected),\n",
    "    \"breakdown\": {\n",
    "        \"must_have_coverage\": round(weights[\"must_have_coverage\"] * must_cov, 2),\n",
    "        \"required_coverage\": round(weights[\"required_coverage\"] * req_cov, 2),\n",
    "        \"preferred_coverage\": round(weights[\"preferred_coverage\"] * pref_cov, 2),\n",
    "        \"role_alignment\": round(weights[\"role_alignment\"] * role_alignment, 2),\n",
    "        \"project_alignment\": round(weights[\"project_alignment\"] * project_alignment, 2),\n",
    "        \"evidence_depth\": round(weights[\"evidence_depth\"] * evidence_depth, 2),\n",
    "        \"seniority_fit\": round(weights[\"seniority_fit\"] * seniority_fit, 2),\n",
    "        \"responsibility_overlap\": round(weights[\"responsibility_overlap\"] * resp_cover, 2),\n",
    "        \"soft_penalties\": {\n",
    "            \"missing_many_must_haves\": int(len(missing_must) > 4) * 5,\n",
    "            \"degree_missing_penalty\": (3 if (degree_required and not has_degree) else 0),\n",
    "            \"zero_metrics_penalty\": (3 if metric_count == 0 else 0),\n",
    "            \"location_penalty\": location_soft_penalty,\n",
    "        },\n",
    "        \"hard_gate_cap\": (opts.get(\"gate_hard_cap\", 59) if failed_gates else None),\n",
    "    },\n",
    "    \"reasons\": reasons,\n",
    "    \"strong_matches\": strong_matches,\n",
    "    \"skill_gaps\": gaps,\n",
    "    \"risk_flags\": risk_flags,\n",
    "    \"gates\": {\n",
    "        \"failed\": failed_gates,\n",
    "        \"notes\": gate_notes,\n",
    "    },\n",
    "}\n",
    "\n",
    "if STATE[\"options\"].get(\"keep_artifacts\", True):\n",
    "    Path(STATE[\"artifacts\"][\"base_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "    with open(STATE[\"artifacts\"][\"paths\"][\"final_json\"], \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(STATE[\"final\"], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"[ok] Final score: {STATE['final']['score_100']}/100  | selected={STATE['final']['selected']}\")\n",
    "print(\"[ok] Breakdown:\", json.dumps(STATE[\"final\"][\"breakdown\"], indent=2))\n",
    "print(\"[ok] Reasons:\", *STATE[\"final\"][\"reasons\"], sep=\"\\n  - \")\n",
    "print(\"[ok] Strong matches:\", \", \".join(STATE[\"final\"][\"strong_matches\"]) or \"‚Äî\")\n",
    "print(\"[ok] Gaps:\", \", \".join(STATE[\"final\"][\"skill_gaps\"]) or \"‚Äî\")\n",
    "print(\"[ok] Risk flags:\", \", \".join(STATE[\"final\"][\"risk_flags\"]) or \"‚Äî\")\n",
    "print(f\"[ok] Saved ‚Üí {STATE['artifacts']['paths']['final_json']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306db06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
